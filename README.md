Our research centered on creating a multi-modal chatbot capable of communicating with users via text, speech, and hand gestures.
The main goal was to develop a versatile and inclusive communication system that could accommodate a wide range of user preferences and needs.
For text and speech processing, we used forward propagation neural networks with crisp logic.
These neural networks produced outputs based on the likelihood of each possible answer.
We used a random forest model for hand sign processing, which predicted gestures with great accuracy.
One important discovery was that the neural network performed best when the probability threshold approached 75%. 
This ideal threshold was discovered via a methodical brute force technique.
